import cv2
import numpy as np
import mediapipe as mp
from PIL import Image, ImageDraw, ImageFont

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)

cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # –ó–µ—Ä–∫–∞–ª—å–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb_frame)

    gesture = "No gesture detected"

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            landmarks = hand_landmarks.landmark

            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–æ–Ω—á–∏–∫–æ–≤ –ø–∞–ª—å—Ü–µ–≤ (–ø–æ –æ—Å–∏ Y)
            thumb_tip = landmarks[4].y
            index_tip = landmarks[8].y
            middle_tip = landmarks[12].y
            ring_tip = landmarks[16].y
            pinky_tip = landmarks[20].y

            fingers = [
                index_tip < landmarks[6].y,  # –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π
                middle_tip < landmarks[10].y,  # –°—Ä–µ–¥–Ω–∏–π
                ring_tip < landmarks[14].y,  # –ë–µ–∑—ã–º—è–Ω–Ω—ã–π
                pinky_tip < landmarks[18].y  # –ú–∏–∑–∏–Ω–µ—Ü
            ]

            if fingers == [False, True, False, False]:
                gesture = "üñï Fuck you"
            elif fingers == [True, True, True, True]:
                gesture = "üñê Open Palm"
            elif fingers == [True, False, False, False]:
                gesture = "‚òùÔ∏è Pointing Up"
            elif fingers == [True, True, False, False]:
                gesture = "‚úåÔ∏è Peace Sign"
            elif fingers == [False, False, False, False] and thumb_tip < index_tip:
                gesture = "üëç Thumbs Up"

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenCV –≤ PIL
    image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(image_pil)

    # –ó–∞–≥—Ä—É–∑–∫–∞ —à—Ä–∏—Ñ—Ç–∞ (–∑–∞–º–µ–Ω–∏ –ø—É—Ç—å –Ω–∞ —Å–≤–æ–π)
    font_path = "arial.ttf"  # –£–±–µ–¥–∏—Å—å, —á—Ç–æ —É —Ç–µ–±—è –µ—Å—Ç—å —ç—Ç–æ—Ç —à—Ä–∏—Ñ—Ç
    try:
        font = ImageFont.truetype(font_path, 40)
    except IOError:
        font = ImageFont.load_default()

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    draw.text((50, 100), gesture, font=font, fill=(0, 255, 0))

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PIL –æ–±—Ä–∞—Ç–Ω–æ –≤ OpenCV
    frame = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    cv2.imshow("Gesture Recognition", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
